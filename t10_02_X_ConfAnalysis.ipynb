{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d5672f-a44b-4115-9b33-3f68018683e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import scipy\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1046e6c8-a7e0-4b01-891d-23fe1c086a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train', 'valid', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096fdbb5-28eb-44b6-afc2-a073cf2cac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_inds = {'XD': {split: [] for split in splits}, \n",
    "                 'XR': {split: [] for split in splits}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bd9f61-cb8d-4062-abdf-aa37e80dc6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('./data/t10_datacut')\n",
    "os.makedirs(path_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f1734-1fe3-4f3a-868b-cffb2a83d14f",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18982361-7a0e-4786-a248-b784cd8cca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ds = Path('./datasets/npz_all/npz/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec94637-1a96-4157-8760-84c785e0ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_type = 'layout'\n",
    "ds_source = 'xla'\n",
    "ds_search = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6909b9b2-522d-4cd3-844b-0d7185ffbba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [02:31,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:15,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid [0, 1, 2, 3, 6, 7, 8, 9, 12, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:02,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    path_files = path_ds / ds_type / ds_source / ds_search / split\n",
    "    files = os.listdir(path_files)\n",
    "    num_files = len(files)\n",
    "    \n",
    "    check_arr = - np.ones((num_files, 18), dtype=np.int8)\n",
    "    \n",
    "    for ix, file in tqdm(enumerate(files)):\n",
    "        npz_data = np.load(path_files / file)\n",
    "        cfeats = npz_data['node_config_feat']\n",
    "        for ifeats in range(18):\n",
    "            check_minus = np.all(cfeats[:,:,ifeats] < - 0.1)\n",
    "            check_arr[ix, ifeats] = check_minus\n",
    "            \n",
    "    for ifeats in range(18):\n",
    "        if not np.all(check_arr[:,ifeats]==1):\n",
    "            non_zero_inds['XD'][split].append(ifeats)\n",
    "\n",
    "    print(split, non_zero_inds['XD'][split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4224f06-7ae9-4006-8e07-25b6c8c9d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_type = 'layout'\n",
    "ds_source = 'xla'\n",
    "ds_search = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "941ca8c7-960e-4cab-8a64-ed2b974cb1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [02:05,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:14,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid [0, 1, 2, 3, 6, 7, 8, 9, 12, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:02,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    path_files = path_ds / ds_type / ds_source / ds_search / split\n",
    "    files = os.listdir(path_files)\n",
    "    num_files = len(files)\n",
    "    \n",
    "    check_arr = - np.ones((num_files, 18), dtype=np.int8)\n",
    "    \n",
    "    for ix, file in tqdm(enumerate(files)):\n",
    "        npz_data = np.load(path_files / file)\n",
    "        cfeats = npz_data['node_config_feat']\n",
    "        for ifeats in range(18):\n",
    "            check_minus = np.all(cfeats[:,:,ifeats] < - 0.1)\n",
    "            check_arr[ix, ifeats] = check_minus\n",
    "            \n",
    "    for ifeats in range(18):\n",
    "        if not np.all(check_arr[:,ifeats]==1):\n",
    "            non_zero_inds['XR'][split].append(ifeats)\n",
    "\n",
    "    print(split, non_zero_inds['XR'][split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "165e801e-b4e8-4d37-bc70-cdb0b78d82e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XD': {'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
       "  'valid': [0, 1, 2, 3, 6, 7, 8, 9, 12, 13],\n",
       "  'test': [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13]},\n",
       " 'XR': {'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
       "  'valid': [0, 1, 2, 3, 6, 7, 8, 9, 12, 13],\n",
       "  'test': [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c89b906-acf5-4134-a4a1-c0e50d14f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data / 'non_zero_inds.X.conf.json', 'w') as fob:\n",
    "    json.dump(non_zero_inds, fob, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37925c-876d-4174-8283-b1724e4da50c",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ec758-e1e1-4ca2-a9e2-9d11992f5efc",
   "metadata": {},
   "source": [
    "### V1 - problem with diff configs / should be used short variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78aff6c4-71d3-4282-b5e1-fb54e914cef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xla_conf_inds = non_zero_inds['XD']['train']\n",
    "xla_conf_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52ad5ef4-1d00-4256-bc00-208f3e11dadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xla_conf_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5deb92b-5c00-4d1c-87e6-54d542bc2b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XD train OK\n",
      "XD valid Problem\n",
      "In common list:\n",
      "{10, 11, 4, 5}\n",
      "In specific list:\n",
      "set()\n",
      "XD test Problem\n",
      "In common list:\n",
      "{11, 5}\n",
      "In specific list:\n",
      "set()\n",
      "XR train OK\n",
      "XR valid Problem\n",
      "In common list:\n",
      "{10, 11, 4, 5}\n",
      "In specific list:\n",
      "set()\n",
      "XR test Problem\n",
      "In common list:\n",
      "{11, 5}\n",
      "In specific list:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "for s in non_zero_inds:\n",
    "    for split in non_zero_inds[s]:\n",
    "        if set(xla_conf_inds) == set(non_zero_inds[s][split]):\n",
    "            print(s, split, 'OK')\n",
    "        else:\n",
    "            print(s, split, 'Problem')\n",
    "            print('In common list:')\n",
    "            print(set(xla_conf_inds) - set(non_zero_inds[s][split]))\n",
    "            print('In specific list:')\n",
    "            print(set(non_zero_inds[s][split]) - set(xla_conf_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9371686b-cd01-4b07-a2fb-2d5a4b148f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data / 'xla_conf_inds.json', 'w') as fob:\n",
    "    json.dump(nlp_conf_inds, fob, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b66ddf-7eb5-4ca5-92ca-5ac599192f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tabqa)",
   "language": "python",
   "name": "tabqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
